version: 2.1
orbs:
  aws-cli: circleci/aws-cli@2.0.3
  kubernetes: circleci/kubernetes@0.12.0
  aws-eks: circleci/aws-eks@1.1.0
jobs:
  build:
    docker:
      - image: cimg/python:3.8.5
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "requirements/common.txt" }}-{{ checksum "requirements/Development.txt" }}
            - v1-dependencies-
      - run:
          name: Install Flask dependencies w/pylint
          command: |
            make setup
            . ~/.cex-api/bin/activate
            make install-dev
      - save_cache:
          paths: ["~/.cex-api"]
          key: v1-dependencies-{{ checksum "requirements/common.txt" }}-{{ checksum "requirements/Development.txt" }}
      - run:
          name: Install Hadolint
          command: |
            sudo wget -O /bin/hadolint https://github.com/hadolint/hadolint/releases/download/v2.5.0/hadolint-Linux-x86_64
            sudo chmod +x /bin/hadolint
      - run:
          name: Run linters
          command: |
            . ~/.cex-api/bin/activate
            make lint
  deploy-docker-image:
    docker:
      - image: cimg/base:2021.07
    steps:
      - checkout
      - setup_remote_docker:
          version: 20.10.6
      - run:
          name: Build and run docker image in detached mode
          command: |
            chmod +x run_docker.sh
            ./run_docker.sh
      - run:
          name: Test that Docker container is up and running
          command: |
            if docker exec $(cat container_id.log) curl --retry 10 --retry-connrefused http://localhost:5000 | grep -s "PRODUCTION"
            then
              echo "Dockerized Flask app is up and running!"
            else
              echo "ERROR: Docker app is down! Exiting..."
              exit 1
            fi
      - run:
          name: Authenticate and upload Docker image to DockerHub
          command: |
            echo "$DOCKERHUB_PASSWORD" | docker login -u "$DOCKERHUB_USERNAME" --password-stdin
            docker push ${DOCKERHUB_USERNAME}/currency-exchange:prod
  deploy-infrastructure:
    docker:
      - image: cimg/base:2021.07
    steps: 
      - checkout
      - aws-cli/install
      - aws-eks/install-eksctl
      - kubernetes/install-kubectl
      # - run:
      #     name: Install eksctl CLI
      #     command: |
      #       curl --silent \
      #         --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
      #       sudo mv /tmp/eksctl /usr/local/bin
      #       eksctl version
      # - run:
      #     name: Install kubectl and export it to path
      #     command: |
      #       curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
      #       chmod +x kubectl
      #       mkdir -p ~/.local/bin/kubectl
      #       mv ./kubectl ~/.local/bin/kubectl
      #       echo "export PATH=~/.local/bin/kubectl:$PATH" >> $BASH_ENV
      - run:
          name: Deploy EKS Cluster, Network & Cluster Cloudformation Stacks
          command: |
            cd .circleci/cloudformation

            ./deploy-stack.sh -n udacity-capstone-network \
              -f stacks/network.yml \
              -t "project=udacity-capstone workflow=${CIRCLE_WORKFLOW_ID}"

            ./deploy-stack.sh -n udacity-capstone-cluster \
              -f stacks/cluster.yml -c \
              -t "project=udacity-capstone workflow=${CIRCLE_WORKFLOW_ID}"
      - run:
          name: Update kubeconfig and check that svc is running
          command: |
            aws eks update-kubeconfig \
              --region eu-west-2 \
              --name udacity-cluster
  
            kubectl get svc
      - run:
          name: Associate OIDC provider with EKS cluster, if not already associated
          command: |
            eksctl utils associate-iam-oidc-provider --cluster udacity-cluster --approve
      - run:
          name: Create service account and attach CNI addon
          command: |
            eksctl create iamserviceaccount \
              --name aws-node \
              --namespace kube-system \
              --cluster udacity-cluster \
              --attach-policy-arn arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy \
              --approve \
              --override-existing-serviceaccounts
      - run:
          name: Deploy EKS Nodegroup (Private Subnets)
          command: |
            ./deploy-stack.sh -n udacity-capstone-nodegroup \
              -f stacks/nodegroup.yml -c \
              -t "project=udacity-capstone workflow=${CIRCLE_WORKFLOW_ID}"
      # - persist_to_workspace:
      #     root:  ~/.local/bin
      #     paths:
      #       - kubectl
  configure-infrastructure:
    docker:
      - image: cimg/base:2021.07
    steps: 
      - checkout
      - aws-cli/install
      - aws-eks/install-eksctl
      - kubernetes/install-kubectl
      # - run:
      #     name: Install eksctl CLI
      #     command: |
      #       curl --silent \
      #         --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
      #       sudo mv /tmp/eksctl /usr/local/bin
      #       eksctl version
      # - attach_workspace:
      #     at: ~/.local/bin
      - run:
          name: Export path for kubectl
          command: |
            # echo "export PATH=~/.local/bin/kubectl:$PATH" >> $BASH_ENV
            aws eks update-kubeconfig \
              --region eu-west-2 \
              --name udacity-cluster
      - run:
          name: Deploy AWS Load Balancer Controller, if not already deployed
          command: |
            if ! (( kubectl get deployment -n kube-system aws-load-balancer-controller )) ; then
              eksctl create iamserviceaccount \
                --cluster=udacity-cluster \
                --namespace=kube-system \
                --name=aws-load-balancer-controller \
                --attach-policy-arn=arn:aws:iam::${AWS_Account_Id}:policy/AWSLoadBalancerControllerIAMPolicy \
                --override-existing-serviceaccounts \
                --approve
              
              kubectl apply \
                  --validate=false \
                  -f https://github.com/jetstack/cert-manager/releases/download/v1.1.1/cert-manager.yaml
              
              cd kubernetes/
              kubectl apply -f aws-load-balancer-controller-v2.2.0.yaml
            fi
      - run:
          name: Check that AWS controller is running
          command: |
            kubectl get deployment -n kube-system aws-load-balancer-controller

workflows:
  default:
    jobs:
      - build
      - deploy-docker-image:
          requires: [build]
      - deploy-infrastructure:
          requires: [deploy-docker-image]
      - configure-infrastructure:
          requires: [deploy-infrastructure]
